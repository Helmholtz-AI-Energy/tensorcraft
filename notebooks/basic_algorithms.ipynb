{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D and 3D Matrix Multiplication\n",
    "## Setup\n",
    "### Installation\n",
    "```pip install ipyparallel```\n",
    "\n",
    "or \n",
    "\n",
    "```pip install -e .[notebook]```\n",
    "\n",
    "### Start cluster\n",
    "\n",
    "```ipcluster start -n 4 --engines=MPI --profile mpi```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "rc = ipp.Client(profile='mpi')\n",
    "rc.wait_for_engines(4)\n",
    "len(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import torch\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "print(f'Hello from rank {rank}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "cart_comm = comm.Create_cart(dims=[2, 2], periods=[True, True], reorder=True)\n",
    "print(f'Hello from rank {rank}! My coordinates are {cart_comm.Get_coords(rank)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "print(f\"Topo: {cart_comm.Get_topo()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "row_comm = cart_comm.Sub([0,1])\n",
    "row_global_ranks = row_comm.allgather(rank)\n",
    "print(f'Hello from rank {rank}! In my row, the ranks are {row_global_ranks}')\n",
    "\n",
    "col_comm = cart_comm.Sub([1,0])\n",
    "col_global_ranks = col_comm.allgather(rank)\n",
    "print(f'Hello from rank {rank}! In my col, the ranks are {col_global_ranks}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "def as_buffer(x: torch.Tensor):\n",
    "    return MPI.buffer.fromaddress(x.untyped_storage().data_ptr(), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Vector\n",
    "\n",
    "### y:= Ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "A_g = torch.arange(64).reshape(8, 8)\n",
    "A_l = A_g[col_comm.Get_rank()::2, row_comm.Get_rank()::2].contiguous()\n",
    "print(\"A_local:\", A_l)\n",
    "\n",
    "x_g = torch.arange(8).reshape(8, 1)\n",
    "x_l = x_g[comm.Get_rank()::comm.Get_size(), :].contiguous()\n",
    "print(\"x_local:\", x_l)\n",
    "\n",
    "\n",
    "# x_col = torch.zeros(4,1, dtype=torch.long)\n",
    "# col_comm.Allgather((as_buffer(x_l), 2, MPI.LONG), (as_buffer(x_col), 2, MPI.LONG))\n",
    "# x_col = x_col.reshape(2,2).T.reshape(4,1).contiguous()\n",
    "# print(\"x_gather_col:\", x_col)\n",
    "\n",
    "x_col = torch.zeros(4,1, dtype=torch.long)\n",
    "data_type = MPI.LONG.Create_vector(2, 1, 2).Create_resized(MPI.LONG.Get_extent()[0], MPI.LONG.Get_extent()[1]).Commit()\n",
    "col_comm.Allgather((as_buffer(x_l), 2, MPI.LONG), (as_buffer(x_col), 1, data_type))\n",
    "print(\"x_gather_col:\", x_col)\n",
    "\n",
    "y_l = A_l @ x_col\n",
    "print(\"y_local:\", y_l)\n",
    "\n",
    "y_l = y_l.reshape(2,2).T.reshape(4,1).contiguous()\n",
    "y_scatter = torch.zeros(2, 1, dtype=torch.long)\n",
    "row_comm.Reduce_scatter((as_buffer(y_l), 4, MPI.LONG), (as_buffer(y_scatter), 2, MPI.LONG), [2,2], MPI.SUM)\n",
    "print(\"y_scatter:\", y_scatter)\n",
    "\n",
    "y_end = torch.zeros(2,2,2, dtype=torch.long)\n",
    "comm.Allgather((as_buffer(y_scatter), 2, MPI.LONG), (as_buffer(y_end), 2, MPI.LONG))\n",
    "y_end = y_end.permute(2,1,0).reshape(8,1).contiguous()\n",
    "print(\"y_end:\", y_end)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "print(\"Expected:\", A_g @ x_g)\n",
    "print(\"Actual:\", y_end)\n",
    "torch.allclose(y_end, A_g @ x_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x = A.T * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "A_g = torch.arange(64).reshape(8, 8)\n",
    "A_l = A_g[col_comm.Get_rank()::2, row_comm.Get_rank()::2].contiguous()\n",
    "print(\"A_local:\", A_l)\n",
    "\n",
    "y_g = torch.arange(8).reshape(8, 1)\n",
    "i = col_comm.Get_rank() + col_comm.Get_size() * row_comm.Get_rank()\n",
    "y_l = y_g[i::comm.Get_size(), :].contiguous()\n",
    "print(\"y_local:\", y_l)\n",
    "\n",
    "y_col = torch.zeros(4,1, dtype=torch.long)\n",
    "row_comm.Allgather((as_buffer(y_l), 2, MPI.LONG), (as_buffer(y_col), 2, MPI.LONG))\n",
    "y_col = y_col.reshape(2,2).T.reshape(4,1).contiguous()\n",
    "print(\"y_gather_col:\", y_col)\n",
    "\n",
    "x_l = A_l.T @ y_col\n",
    "print(\"x_local:\", x_l)\n",
    "\n",
    "x_l = x_l.reshape(2,2).T.reshape(4,1).contiguous()\n",
    "x_scatter = torch.zeros(2, 1, dtype=torch.long)\n",
    "col_comm.Reduce_scatter((as_buffer(x_l), 4, MPI.LONG), (as_buffer(x_scatter), 2, MPI.LONG), [2,2], MPI.SUM)\n",
    "print(\"x_scatter:\", x_scatter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "print(\"expected:\", A_g.T @ y_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A := y * x.T + A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "A_g = torch.arange(64).reshape(8, 8)\n",
    "A_l = A_g[col_comm.Get_rank()::2, row_comm.Get_rank()::2].contiguous()\n",
    "print(\"A_local:\", A_l)\n",
    "\n",
    "x_g = torch.arange(8).reshape(8, 1)\n",
    "x_l = x_g[comm.Get_rank()::comm.Get_size(), :].contiguous()\n",
    "print(\"x_local:\", x_l)\n",
    "\n",
    "y_g = torch.arange(8).reshape(8, 1)\n",
    "i = col_comm.Get_rank() + col_comm.Get_size() * row_comm.Get_rank()\n",
    "y_l = y_g[i::comm.Get_size(), :].contiguous()\n",
    "print(\"y_local:\", y_l)\n",
    "\n",
    "x_col = torch.zeros(4,1, dtype=torch.long)\n",
    "col_comm.Allgather((as_buffer(x_l), 2, MPI.LONG), (as_buffer(x_col), 2, MPI.LONG))\n",
    "x_col = x_col.reshape(2,2).T.reshape(4,1).contiguous()\n",
    "print(\"x_gather_col:\", x_col)\n",
    "\n",
    "y_col = torch.zeros(4,1, dtype=torch.long)\n",
    "row_comm.Allgather((as_buffer(y_l), 2, MPI.LONG), (as_buffer(y_col), 2, MPI.LONG))\n",
    "y_col = y_col.reshape(2,2).T.reshape(4,1).contiguous()\n",
    "print(\"y_gather_col:\", y_col)\n",
    "\n",
    "Z_l = y_col @ x_col.T + A_l\n",
    "print(\"Z_local:\", Z_l)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "print(f\"Expected: {y_g @ x_g.T + A_g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create_darray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "if comm.Get_rank() == 0:\n",
    "    A = torch.arange(64).reshape(8, 8)\n",
    "    print(A)\n",
    "    print(A.dtype)\n",
    "\n",
    "    darray_type = MPI.LONG.Create_darray(\n",
    "        4,                    # Size\n",
    "        1,                      # Rank\n",
    "        # 2,                      # number of array dimensions (as well as process grid dimensions)\n",
    "        [64,1],                 # size of the global array\n",
    "        [MPI.DISTRIBUTE_CYCLIC, MPI.DISTRIBUTE_NONE], # distribution type\n",
    "        [1, 1], # distribution argument\n",
    "        [4, 1],                 # size of the process grid\n",
    "        MPI.ORDER_C,            # array storage order\n",
    "    ).Commit()\n",
    "\n",
    "    # comm.Send(buf=[as_buffer(A), 8, MPI.LONG], dest=1)\n",
    "    comm.Send([as_buffer(A), 1, darray_type], dest=1, tag=55)\n",
    "\n",
    "    darray_type.Free() \n",
    "\n",
    "elif comm.Get_rank() == 1:\n",
    "    A = torch.zeros(4, 4, dtype=torch.int64)\n",
    "\n",
    "    # comm.Recv(buf=[as_buffer(A), 8, MPI.LONG], source=0)\n",
    "    comm.Recv([as_buffer(A), 16, MPI.LONG], source=0, tag=55)\n",
    "    print(A)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorcraft-dev-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
