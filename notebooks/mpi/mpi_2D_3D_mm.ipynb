{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D and 3D Matrix Multiplication\n",
    "## Setup\n",
    "### Installation\n",
    "```pip install ipyparallel```\n",
    "\n",
    "or \n",
    "\n",
    "```pip install -e .[notebook]```\n",
    "\n",
    "### Start cluster\n",
    "\n",
    "```ipcluster start -n 4 --engines=MPI --profile mpi```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "rc = ipp.Client(profile='mpi')\n",
    "rc.wait_for_engines(4)\n",
    "len(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import torch\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "print(f'Hello from rank {rank}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "cart_comm = comm.Create_cart(dims=[2, 2], periods=[True, True], reorder=True)\n",
    "print(f'Hello from rank {rank}! My coordinates are {cart_comm.Get_coords(rank)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "print(f\"Topo: {cart_comm.Get_topo()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "row_comm = cart_comm.Sub([0,1])\n",
    "row_global_ranks = row_comm.allgather(rank)\n",
    "print(f'Hello from rank {rank}! In my row, the ranks are {row_global_ranks}')\n",
    "\n",
    "col_comm = cart_comm.Sub([1,0])\n",
    "col_global_ranks = col_comm.allgather(rank)\n",
    "print(f'Hello from rank {rank}! In my col, the ranks are {col_global_ranks}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "def as_buffer(x: torch.Tensor):\n",
    "    return MPI.buffer.fromaddress(x.untyped_storage().data_ptr(), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Vector\n",
    "\n",
    "### y:= Ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "A_g = torch.arange(64).reshape(8, 8)\n",
    "A_l = A_g[col_comm.Get_rank()::2, row_comm.Get_rank()::2].contiguous()\n",
    "print(\"A_local:\", A_l)\n",
    "\n",
    "x_g = torch.arange(8).reshape(8, 1)\n",
    "x_l = x_g[comm.Get_rank()::comm.Get_size(), :].contiguous()\n",
    "print(\"x_local:\", x_l)\n",
    "\n",
    "\n",
    "# x_col = torch.zeros(4,1, dtype=torch.long)\n",
    "# col_comm.Allgather((as_buffer(x_l), 2, MPI.LONG), (as_buffer(x_col), 2, MPI.LONG))\n",
    "# x_col = x_col.reshape(2,2).T.reshape(4,1).contiguous()\n",
    "# print(\"x_gather_col:\", x_col)\n",
    "\n",
    "x_col = torch.zeros(4,1, dtype=torch.long)\n",
    "data_type = MPI.LONG.Create_vector(2, 1, 2).Create_resized(MPI.LONG.Get_extent()[0], MPI.LONG.Get_extent()[1]).Commit()\n",
    "col_comm.Allgather((as_buffer(x_l), 2, MPI.LONG), (as_buffer(x_col), 1, data_type))\n",
    "print(\"x_gather_col:\", x_col)\n",
    "\n",
    "y_l = A_l @ x_col\n",
    "print(\"y_local:\", y_l)\n",
    "\n",
    "y_l = y_l.reshape(2,2).T.reshape(4,1).contiguous()\n",
    "y_scatter = torch.zeros(2, 1, dtype=torch.long)\n",
    "row_comm.Reduce_scatter((as_buffer(y_l), 4, MPI.LONG), (as_buffer(y_scatter), 2, MPI.LONG), [2,2], MPI.SUM)\n",
    "print(\"y_scatter:\", y_scatter)\n",
    "\n",
    "y_end = torch.zeros(2,2,2, dtype=torch.long)\n",
    "comm.Allgather((as_buffer(y_scatter), 2, MPI.LONG), (as_buffer(y_end), 2, MPI.LONG))\n",
    "y_end = y_end.permute(2,1,0).reshape(8,1).contiguous()\n",
    "print(\"y_end:\", y_end)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "print(\"Expected:\", A_g @ x_g)\n",
    "print(\"Actual:\", y_end)\n",
    "torch.allclose(y_end, A_g @ x_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x = A.T * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "A_g = torch.arange(64).reshape(8, 8)\n",
    "A_l = A_g[col_comm.Get_rank()::2, row_comm.Get_rank()::2].contiguous()\n",
    "print(\"A_local:\", A_l)\n",
    "\n",
    "y_g = torch.arange(8).reshape(8, 1)\n",
    "i = col_comm.Get_rank() + col_comm.Get_size() * row_comm.Get_rank()\n",
    "y_l = y_g[i::comm.Get_size(), :].contiguous()\n",
    "print(\"y_local:\", y_l)\n",
    "\n",
    "y_col = torch.zeros(4,1, dtype=torch.long)\n",
    "row_comm.Allgather((as_buffer(y_l), 2, MPI.LONG), (as_buffer(y_col), 2, MPI.LONG))\n",
    "y_col = y_col.reshape(2,2).T.reshape(4,1).contiguous()\n",
    "print(\"y_gather_col:\", y_col)\n",
    "\n",
    "x_l = A_l.T @ y_col\n",
    "print(\"x_local:\", x_l)\n",
    "\n",
    "x_l = x_l.reshape(2,2).T.reshape(4,1).contiguous()\n",
    "x_scatter = torch.zeros(2, 1, dtype=torch.long)\n",
    "col_comm.Reduce_scatter((as_buffer(x_l), 4, MPI.LONG), (as_buffer(x_scatter), 2, MPI.LONG), [2,2], MPI.SUM)\n",
    "print(\"x_scatter:\", x_scatter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "print(\"expected:\", A_g.T @ y_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A := y * x.T + A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "A_g = torch.arange(64).reshape(8, 8)\n",
    "A_l = A_g[col_comm.Get_rank()::2, row_comm.Get_rank()::2].contiguous()\n",
    "print(\"A_local:\", A_l)\n",
    "\n",
    "x_g = torch.arange(8).reshape(8, 1)\n",
    "x_l = x_g[comm.Get_rank()::comm.Get_size(), :].contiguous()\n",
    "print(\"x_local:\", x_l)\n",
    "\n",
    "y_g = torch.arange(8).reshape(8, 1)\n",
    "i = col_comm.Get_rank() + col_comm.Get_size() * row_comm.Get_rank()\n",
    "y_l = y_g[i::comm.Get_size(), :].contiguous()\n",
    "print(\"y_local:\", y_l)\n",
    "\n",
    "x_col = torch.zeros(4,1, dtype=torch.long)\n",
    "col_comm.Allgather((as_buffer(x_l), 2, MPI.LONG), (as_buffer(x_col), 2, MPI.LONG))\n",
    "x_col = x_col.reshape(2,2).T.reshape(4,1).contiguous()\n",
    "print(\"x_gather_col:\", x_col)\n",
    "\n",
    "y_col = torch.zeros(4,1, dtype=torch.long)\n",
    "row_comm.Allgather((as_buffer(y_l), 2, MPI.LONG), (as_buffer(y_col), 2, MPI.LONG))\n",
    "y_col = y_col.reshape(2,2).T.reshape(4,1).contiguous()\n",
    "print(\"y_gather_col:\", y_col)\n",
    "\n",
    "Z_l = y_col @ x_col.T + A_l\n",
    "print(\"Z_local:\", Z_l)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "print(f\"Expected: {y_g @ x_g.T + A_g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create_darray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "if comm.Get_rank() == 0:\n",
    "    A = torch.arange(64).reshape(8, 8)\n",
    "    print(A)\n",
    "    print(A.dtype)\n",
    "\n",
    "    darray_type = MPI.LONG.Create_darray(\n",
    "        4,                    # Size\n",
    "        1,                      # Rank\n",
    "        # 2,                      # number of array dimensions (as well as process grid dimensions)\n",
    "        [64,1],                 # size of the global array\n",
    "        [MPI.DISTRIBUTE_CYCLIC, MPI.DISTRIBUTE_NONE], # distribution type\n",
    "        [1, 1], # distribution argument\n",
    "        [4, 1],                 # size of the process grid\n",
    "        MPI.ORDER_C,            # array storage order\n",
    "    ).Commit()\n",
    "\n",
    "    # comm.Send(buf=[as_buffer(A), 8, MPI.LONG], dest=1)\n",
    "    comm.Send([as_buffer(A), 1, darray_type], dest=1, tag=55)\n",
    "\n",
    "    darray_type.Free() \n",
    "\n",
    "elif comm.Get_rank() == 1:\n",
    "    A = torch.zeros(4, 4, dtype=torch.int64)\n",
    "\n",
    "    # comm.Recv(buf=[as_buffer(A), 8, MPI.LONG], source=0)\n",
    "    comm.Recv([as_buffer(A), 16, MPI.LONG], source=0, tag=55)\n",
    "    print(A)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Item Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import tensorcraft as tc\n",
    "comm = MPI.COMM_WORLD\n",
    "## Let's find the maximum element count on my mpi implementation\n",
    "options = [torch.iinfo(torch.int32).max]\n",
    "\n",
    "for possible_max in options:\n",
    "    print(f\"Trying {possible_max}\")\n",
    "    if comm.Get_rank() == 0:\n",
    "        A = torch.ones(possible_max, dtype=torch.bool)\n",
    "        print(A.dtype)\n",
    "        print(A[:10])\n",
    "\n",
    "        print(f\"Sending {possible_max} elements, {possible_max / 10**9} Gb\")\n",
    "\n",
    "    else:\n",
    "        A = torch.zeros(possible_max, dtype=torch.bool)\n",
    "\n",
    "    comm.Bcast(buf=[tc.mpi4torch.as_buffer(A), possible_max, MPI.BOOL], root=0)\n",
    "\n",
    "    if comm.Get_rank() == 0:\n",
    "        print(\"Sent!\")\n",
    "    else:\n",
    "        print(\"Received!\")\n",
    "        print(A[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interweave allgather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359afc0cd7d14140aaf3240f40e28503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?engine/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipyparallel as ipp\n",
    "rc = ipp.Client(profile='mpi')\n",
    "rc.wait_for_engines(2)\n",
    "len(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:1] Hello from rank 1!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] Hello from rank 2!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:3] Hello from rank 3!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Hello from rank 0!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "import torch\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "print(f'Hello from rank {rank}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] tensor([[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14],\n",
       "        [60, 61, 62, 63, 64],\n",
       "        [65, 66, 67, 68, 69],\n",
       "        [70, 71, 72, 73, 74]])\n",
       "torch.Size([6, 5])\n",
       "torch.int64\n",
       "True\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] tensor([[30, 31, 32, 33, 34],\n",
       "        [35, 36, 37, 38, 39],\n",
       "        [40, 41, 42, 43, 44]])\n",
       "torch.Size([3, 5])\n",
       "torch.int64\n",
       "True\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1] tensor([[15, 16, 17, 18, 19],\n",
       "        [20, 21, 22, 23, 24],\n",
       "        [25, 26, 27, 28, 29],\n",
       "        [75, 76, 77, 78, 79],\n",
       "        [80, 81, 82, 83, 84],\n",
       "        [85, 86, 87, 88, 89]])\n",
       "torch.Size([6, 5])\n",
       "torch.int64\n",
       "True\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:3] tensor([[45, 46, 47, 48, 49],\n",
       "        [50, 51, 52, 53, 54],\n",
       "        [55, 56, 57, 58, 59]])\n",
       "torch.Size([3, 5])\n",
       "torch.int64\n",
       "True\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "import tensorcraft as tc\n",
    "\n",
    "x = torch.arange(90).reshape(18, 5)\n",
    "mesh = torch.Size([4])\n",
    "dist = tc.dist.MultiAxisDist(mesh, ((0,), None), 3)\n",
    "\n",
    "x_local = dist.apply(x, rank)\n",
    "print(x_local)\n",
    "print(x_local.shape)\n",
    "print(x_local.dtype)\n",
    "print(x_local.is_contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:3] (<mpi4py.MPI.buffer object at 0x7beeb8cd6b80>, 15, <mpi4py.MPI.Datatype object at 0x7befb9d10b70>)\n",
       "<mpi4py.MPI.buffer object at 0x7beeb8cd6aa0>\n",
       "tensor([[[[ 0,  1,  2,  3,  4],\n",
       "          [ 5,  6,  7,  8,  9],\n",
       "          [10, 11, 12, 13, 14]],\n",
       "\n",
       "         [[60, 61, 62, 63, 64],\n",
       "          [65, 66, 67, 68, 69],\n",
       "          [70, 71, 72, 73, 74]]],\n",
       "\n",
       "\n",
       "        [[[15, 16, 17, 18, 19],\n",
       "          [20, 21, 22, 23, 24],\n",
       "          [25, 26, 27, 28, 29]],\n",
       "\n",
       "         [[75, 76, 77, 78, 79],\n",
       "          [80, 81, 82, 83, 84],\n",
       "          [85, 86, 87, 88, 89]]],\n",
       "\n",
       "\n",
       "        [[[30, 31, 32, 33, 34],\n",
       "          [35, 36, 37, 38, 39],\n",
       "          [40, 41, 42, 43, 44]],\n",
       "\n",
       "         [[ 0,  0,  0,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0]]],\n",
       "\n",
       "\n",
       "        [[[45, 46, 47, 48, 49],\n",
       "          [50, 51, 52, 53, 54],\n",
       "          [55, 56, 57, 58, 59]],\n",
       "\n",
       "         [[ 0,  0,  0,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0]]]])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] (<mpi4py.MPI.buffer object at 0x7b8c937cebf0>, 30, <mpi4py.MPI.Datatype object at 0x7b8d949e4c60>)\n",
       "<mpi4py.MPI.buffer object at 0x7b8c937cea30>\n",
       "tensor([[[[ 0,  1,  2,  3,  4],\n",
       "          [ 5,  6,  7,  8,  9],\n",
       "          [10, 11, 12, 13, 14]],\n",
       "\n",
       "         [[60, 61, 62, 63, 64],\n",
       "          [65, 66, 67, 68, 69],\n",
       "          [70, 71, 72, 73, 74]]],\n",
       "\n",
       "\n",
       "        [[[15, 16, 17, 18, 19],\n",
       "          [20, 21, 22, 23, 24],\n",
       "          [25, 26, 27, 28, 29]],\n",
       "\n",
       "         [[75, 76, 77, 78, 79],\n",
       "          [80, 81, 82, 83, 84],\n",
       "          [85, 86, 87, 88, 89]]],\n",
       "\n",
       "\n",
       "        [[[30, 31, 32, 33, 34],\n",
       "          [35, 36, 37, 38, 39],\n",
       "          [40, 41, 42, 43, 44]],\n",
       "\n",
       "         [[ 0,  0,  0,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0]]],\n",
       "\n",
       "\n",
       "        [[[45, 46, 47, 48, 49],\n",
       "          [50, 51, 52, 53, 54],\n",
       "          [55, 56, 57, 58, 59]],\n",
       "\n",
       "         [[ 0,  0,  0,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0]]]])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1] (<mpi4py.MPI.buffer object at 0x7591129f6790>, 30, <mpi4py.MPI.Datatype object at 0x759213b649f0>)\n",
       "<mpi4py.MPI.buffer object at 0x7591129f69c0>\n",
       "tensor([[[[ 0,  1,  2,  3,  4],\n",
       "          [ 5,  6,  7,  8,  9],\n",
       "          [10, 11, 12, 13, 14]],\n",
       "\n",
       "         [[60, 61, 62, 63, 64],\n",
       "          [65, 66, 67, 68, 69],\n",
       "          [70, 71, 72, 73, 74]]],\n",
       "\n",
       "\n",
       "        [[[15, 16, 17, 18, 19],\n",
       "          [20, 21, 22, 23, 24],\n",
       "          [25, 26, 27, 28, 29]],\n",
       "\n",
       "         [[75, 76, 77, 78, 79],\n",
       "          [80, 81, 82, 83, 84],\n",
       "          [85, 86, 87, 88, 89]]],\n",
       "\n",
       "\n",
       "        [[[30, 31, 32, 33, 34],\n",
       "          [35, 36, 37, 38, 39],\n",
       "          [40, 41, 42, 43, 44]],\n",
       "\n",
       "         [[ 0,  0,  0,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0]]],\n",
       "\n",
       "\n",
       "        [[[45, 46, 47, 48, 49],\n",
       "          [50, 51, 52, 53, 54],\n",
       "          [55, 56, 57, 58, 59]],\n",
       "\n",
       "         [[ 0,  0,  0,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0]]]])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] (<mpi4py.MPI.buffer object at 0x7f466f792640>, 15, <mpi4py.MPI.Datatype object at 0x7f476e1dca50>)\n",
       "<mpi4py.MPI.buffer object at 0x7f466cfca9c0>\n",
       "tensor([[[[ 0,  1,  2,  3,  4],\n",
       "          [ 5,  6,  7,  8,  9],\n",
       "          [10, 11, 12, 13, 14]],\n",
       "\n",
       "         [[60, 61, 62, 63, 64],\n",
       "          [65, 66, 67, 68, 69],\n",
       "          [70, 71, 72, 73, 74]]],\n",
       "\n",
       "\n",
       "        [[[15, 16, 17, 18, 19],\n",
       "          [20, 21, 22, 23, 24],\n",
       "          [25, 26, 27, 28, 29]],\n",
       "\n",
       "         [[75, 76, 77, 78, 79],\n",
       "          [80, 81, 82, 83, 84],\n",
       "          [85, 86, 87, 88, 89]]],\n",
       "\n",
       "\n",
       "        [[[30, 31, 32, 33, 34],\n",
       "          [35, 36, 37, 38, 39],\n",
       "          [40, 41, 42, 43, 44]],\n",
       "\n",
       "         [[ 0,  0,  0,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0]]],\n",
       "\n",
       "\n",
       "        [[[45, 46, 47, 48, 49],\n",
       "          [50, 51, 52, 53, 54],\n",
       "          [55, 56, 57, 58, 59]],\n",
       "\n",
       "         [[ 0,  0,  0,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0]]]])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "gathered = torch.zeros(4, 2, 3, 5, dtype=torch.int64)\n",
    "\n",
    "send_buf = tc.util.tensor2mpiBuffer(x_local)\n",
    "print(send_buf)\n",
    "recv_buf = tc.util.as_buffer(gathered)\n",
    "print(recv_buf)\n",
    "\n",
    "comm.Allgather(send_buf, (recv_buf, 30, MPI.LONG))\n",
    "print(gathered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:1] tensor([[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19],\n",
       "        [20, 21, 22, 23, 24],\n",
       "        [25, 26, 27, 28, 29],\n",
       "        [30, 31, 32, 33, 34],\n",
       "        [35, 36, 37, 38, 39],\n",
       "        [40, 41, 42, 43, 44],\n",
       "        [45, 46, 47, 48, 49],\n",
       "        [50, 51, 52, 53, 54],\n",
       "        [55, 56, 57, 58, 59],\n",
       "        [60, 61, 62, 63, 64],\n",
       "        [65, 66, 67, 68, 69],\n",
       "        [70, 71, 72, 73, 74],\n",
       "        [75, 76, 77, 78, 79],\n",
       "        [80, 81, 82, 83, 84],\n",
       "        [85, 86, 87, 88, 89],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0]])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:3] tensor([[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19],\n",
       "        [20, 21, 22, 23, 24],\n",
       "        [25, 26, 27, 28, 29],\n",
       "        [30, 31, 32, 33, 34],\n",
       "        [35, 36, 37, 38, 39],\n",
       "        [40, 41, 42, 43, 44],\n",
       "        [45, 46, 47, 48, 49],\n",
       "        [50, 51, 52, 53, 54],\n",
       "        [55, 56, 57, 58, 59],\n",
       "        [60, 61, 62, 63, 64],\n",
       "        [65, 66, 67, 68, 69],\n",
       "        [70, 71, 72, 73, 74],\n",
       "        [75, 76, 77, 78, 79],\n",
       "        [80, 81, 82, 83, 84],\n",
       "        [85, 86, 87, 88, 89],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0]])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] tensor([[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19],\n",
       "        [20, 21, 22, 23, 24],\n",
       "        [25, 26, 27, 28, 29],\n",
       "        [30, 31, 32, 33, 34],\n",
       "        [35, 36, 37, 38, 39],\n",
       "        [40, 41, 42, 43, 44],\n",
       "        [45, 46, 47, 48, 49],\n",
       "        [50, 51, 52, 53, 54],\n",
       "        [55, 56, 57, 58, 59],\n",
       "        [60, 61, 62, 63, 64],\n",
       "        [65, 66, 67, 68, 69],\n",
       "        [70, 71, 72, 73, 74],\n",
       "        [75, 76, 77, 78, 79],\n",
       "        [80, 81, 82, 83, 84],\n",
       "        [85, 86, 87, 88, 89],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0]])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] tensor([[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19],\n",
       "        [20, 21, 22, 23, 24],\n",
       "        [25, 26, 27, 28, 29],\n",
       "        [30, 31, 32, 33, 34],\n",
       "        [35, 36, 37, 38, 39],\n",
       "        [40, 41, 42, 43, 44],\n",
       "        [45, 46, 47, 48, 49],\n",
       "        [50, 51, 52, 53, 54],\n",
       "        [55, 56, 57, 58, 59],\n",
       "        [60, 61, 62, 63, 64],\n",
       "        [65, 66, 67, 68, 69],\n",
       "        [70, 71, 72, 73, 74],\n",
       "        [75, 76, 77, 78, 79],\n",
       "        [80, 81, 82, 83, 84],\n",
       "        [85, 86, 87, 88, 89],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0]])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "print(gathered.permute(1, 0, 2, 3).reshape(24, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorcraft-dev-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
