{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPI Custom Datatypes + Torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Installation\n",
    "```pip install ipyparallel```\n",
    "\n",
    "or \n",
    "\n",
    "```pip install -e .[notebook]```\n",
    "\n",
    "### Start cluster\n",
    "\n",
    "```ipcluster start -n 4 --engines=MPI --profile mpi```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipyparallel as ipp\n",
    "rc = ipp.Client(profile='mpi')\n",
    "rc.wait_for_engines(4)\n",
    "len(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:1] Hello from rank 1!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:3] Hello from rank 3!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Hello from rank 0!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] Hello from rank 2!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "import torch\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "print(f'Hello from rank {rank}!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large item count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:3] Trying 2147483647\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] Trying 2147483647\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1] Trying 2147483647\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Trying 2147483647\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0:execute]\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n",
      "\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpossible_max\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m comm\u001b[38;5;241m.\u001b[39mGet_rank() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;32m----> 8\u001b[0m     A \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossible_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(A\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(A[:\u001b[38;5;241m10\u001b[39m])\n",
      "\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"normal_kernel_cpu\" not implemented for 'Int'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef571d172e24b6eadbf0302fb7c97c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "%px:   0%|          | 0/4 [00:00<?, ?tasks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AlreadyDisplayedError",
     "evalue": "4 errors",
     "output_type": "error",
     "traceback": [
      "4 errors"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "comm = MPI.COMM_WORLD\n",
    "## Let's find the maximum element count on my mpi implementation\n",
    "options = [torch.iinfo(torch.int32).max, torch.iinfo(torch.uint32).max, torch.iinfo(torch.int64).max, torch.iinfo(torch.uint64).max]\n",
    "\n",
    "for possible_max in options:\n",
    "    print(f\"Trying {possible_max}\")\n",
    "    if comm.Get_rank() == 0:\n",
    "        A = torch.randn(possible_max)\n",
    "        print(A.dtype)\n",
    "        print(A[:10])\n",
    "\n",
    "        print(f\"Sent {possible_max} elements\")\n",
    "\n",
    "    else:\n",
    "        A = torch.zeros(possible_max, dtype=torch.float32)\n",
    "\n",
    "    MPI.broadcast(buf=[as_buffer(A), possible_max, MPI.FLOAT], root=0)\n",
    "\n",
    "    if comm.Get_rank() == 0:\n",
    "        print(\"Sent!\")\n",
    "    else:\n",
    "        print(\"Received!\")\n",
    "        print(A[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch 2 Datatype\n",
    "\n",
    "Attempt to create a generic function that, given any torch tensor (contiguous, non-contiguous, view, stride, ...), returns a datatype that can write the send/recv the data there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[juan-20w000p2ge:439968] shmem: mmap: an error occurred while determining whether or not /tmp/ompi.juan-20w000p2ge.1000/jf.0/3508994048/shared_mem_cuda_pool.juan-20w000p2ge could be created.\n",
      "[juan-20w000p2ge:439968] create_and_attach: unable to create shared memory BTL coordinating structure :: size 134217728 \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'torch.dtype' object has no attribute 'max'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmpi4py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MPI\n",
      "\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorcraft\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtc\u001b[39;00m\n",
      "\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Contiguous\u001b[39;00m\n",
      "\u001b[1;32m      8\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m64\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/code/tensorcraft/tensorcraft/__init__.py:13\u001b[0m\n",
      "\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorcraft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compiler\n",
      "\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorcraft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m viz\n",
      "\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorcraft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mpi4torch\n",
      "\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorcraft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linear2multiIndex, multi2linearIndex, order2npOrder\n",
      "\u001b[1;32m     16\u001b[0m _compiler \u001b[38;5;241m=\u001b[39m compiler\u001b[38;5;241m.\u001b[39mCompiler()\n",
      "\n",
      "File \u001b[0;32m~/code/tensorcraft/tensorcraft/mpi4torch/__init__.py:1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorcraft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmpi4torch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m as_buffer, tensor2mpiBuffer\n",
      "\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n",
      "\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_buffer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensor2mpiBuffer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m      6\u001b[0m ]\n",
      "\n",
      "File \u001b[0;32m~/code/tensorcraft/tensorcraft/mpi4torch/util.py:7\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tuple, TypeAlias\n",
      "\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# MPIBuffer: TypeAlias = MPI.BufSpec | MPI.BufSpecB | MPI.BufSpecV | MPI.BufSpecW \u001b[39;00m\n",
      "\u001b[0;32m----> 7\u001b[0m MPI_INT_MAX \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\n",
      "\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_buffer\u001b[39m(x: torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MPI\u001b[38;5;241m.\u001b[39mbuffer\u001b[38;5;241m.\u001b[39mfromaddress(x\u001b[38;5;241m.\u001b[39muntyped_storage()\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'torch.dtype' object has no attribute 'max'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Contiguous\n",
    "x = torch.arange(64).reshape(8, 8)\n",
    "print(x)\n",
    "_ = tc.mpi4torch.tensor2mpiBuffer(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Contiguous, permute\n",
    "x = torch.arange(64).reshape(8, 8).permute(1, 0)\n",
    "print(x)\n",
    "_ = tc.mpi4torch.tensor2mpiBuffer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Contiguous, slicing\n",
    "x = torch.arange(64).reshape(8, 8)[:, 1::2]\n",
    "print(x)\n",
    "_ = tc.mpi4torch.tensor2mpiBuffer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Contiguous, slicing and permute\n",
    "x = torch.arange(64).reshape(8, 8)[4:, 1::2].permute(1, 0)\n",
    "print(x)\n",
    "_ = tc.mpi4torch.tensor2mpiBuffer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.randn(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorcraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
