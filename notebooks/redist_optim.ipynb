{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optim Bottom-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from importlib import reload\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "\n",
    "import tensorcraft as tc\n",
    "\n",
    "tc.set_logger_config(level = logging.INFO)\n",
    "\n",
    "ALPHA = 1e-6 # 1 micro second of latency (Maybe bigger)\n",
    "BETA=64.0/( 200.0 * 1e9) # 200 GBits per second bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Step #\", \"Operation\", \"Distribution\", \"Cost[s]\", \"Memory Usage [MB]\"]\n",
    "columns_width = [8, 20, 40, 8, 8]\n",
    "\n",
    "type_size = 8\n",
    "\n",
    "def print_path(path: list[tuple[str, any, float]], tensor_shape: torch.Size):\n",
    "\n",
    "    line = \" & \".join(f\"{col:<{width}}\" for col, width in zip(columns, columns_width)) + \" \\\\\\\\\"\n",
    "    print(line)\n",
    "    for i, (op, s_dist, s_cost) in enumerate(path):\n",
    "        line = f\"{i:<{columns_width[0]}} & {op:<{columns_width[1]}} & {s_dist.latexStr():<{columns_width[2]}} & {s_cost:<{columns_width[3]}} & {s_dist.maxNumElements(tensor_shape) * 8 / 10**6:<{columns_width[4]}} \\\\\\\\\" \n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mem_constrained_filter(shape: torch.Size, start_dist: tc.dist.MultiAxisDist, target_dist: tc.dist.MultiAxisDist, current_dist: tc.dist.MultiAxisDist ) -> bool:\n",
    "    max_n_elements = max(start_dist.maxNumElements(shape), target_dist.maxNumElements(shape))\n",
    "    return max_n_elements < current_dist.maxNumElements(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redistributors\n",
    "\n",
    "Given a tensor shape, a starting distribution and a target distribution, creates a sequence of collective ops to reach the target dist while optimizing for different metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 ( Tiled Matrix to Row cyclic)\n",
    "\n",
    "Shifting from a tiled matrix, to a row cyclic distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_shape = torch.Size([100000, 100000])\n",
    "mesh = torch.Size([2,4])\n",
    "dist = tc.dist.MultiAxisDist(mesh, ((0,), (1,),), 100) \n",
    "target_dist = tc.dist.MultiAxisDist(mesh, ((0,1), None), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Gather Split\n",
    "\n",
    "Simplest redistributor. Just allgathers, then splits. Should be both communication and memory ineficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_procs: 8, N_elements: 10000000000\n",
      "Step #   & Operation            & Distribution                             & Cost[s]  & Memory Usage [MB] \\\\\n",
      "0        &                      & $T_{\\perp\\{ 0,1 \\}(100,100)}$            & 0        & 10000.0  \\\\\n",
      "1        & allgather_*          & $T_{\\perp\\{ \\emptyset,\\emptyset \\}(\\emptyset,\\emptyset)}$ & 2.800003 & 80000.0  \\\\\n",
      "2        & split_*              & $T_{\\perp\\{ (0,1),\\emptyset \\}(1,\\emptyset)}$ & 0        & 10000.0  \\\\\n",
      "Total cost: 2.80s\n",
      "CPU times: user 576 ms, sys: 31.3 ms, total: 608 ms\n",
      "Wall time: 535 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "naive_rdist = tc.optim.NaiveGathererRedist(tc.optim.IdealLowerBoundsCM(), alpha=ALPHA, beta=BETA)\n",
    "\n",
    "sequence, total_cost = naive_rdist.redistribute(tensor_shape, dist, target_dist)\n",
    "print_path(sequence, tensor_shape)\n",
    "print(f\"Total cost: {total_cost:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory Constrained (Top K = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explored 13 nodes, found 10 possible paths.\n",
      "Step #   & Operation            & Distribution                             & Cost[s]  & Memory Usage [MB] \\\\\n",
      "0        &                      & $T_{\\perp\\{ 0,1 \\}(100,100)}$            & 0        & 10000.0  \\\\\n",
      "1        & alltoall_0_1_-1      & $T_{\\perp\\{ \\emptyset,(0,1) \\}(\\emptyset,100)}$ & 0.40000099999999994 & 10000.0  \\\\\n",
      "2        & alltoall_minor_1_0_1 & $T_{\\perp\\{ 1,0 \\}(1,400)}$              & 1.200002 & 10000.0  \\\\\n",
      "3        & alltoall_1_0_-1      & $T_{\\perp\\{ (0,1),\\emptyset \\}(1,\\emptyset)}$ & 0.40000099999999994 & 10000.0  \\\\\n",
      "Total cost: 2.000s\n",
      "CPU times: user 1min, sys: 1.15 s, total: 1min 1s\n",
      "Wall time: 42.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mem_constrained_dist = tc.optim.AStarRedistributor(tc.optim.IdealLowerBoundsCM(), alpha=ALPHA, beta=BETA, node_filter=mem_constrained_filter, top_k=10)\n",
    "sequence, total_cost = mem_constrained_dist.redistribute(tensor_shape, dist, target_dist)\n",
    "\n",
    "print_path(sequence, tensor_shape)\n",
    "print(f\"Total cost: {total_cost:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Constrained (Top K = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explored 7 nodes, found 1 possible paths.\n",
      "Step #   & Operation            & Distribution                             & Cost[s]  & Memory Usage [MB] \\\\\n",
      "0        &                      & $T_{\\perp\\{ 0,1 \\}(100,100)}$            & 0        & 10000.0  \\\\\n",
      "1        & changeBlockSize_0_1  & $T_{\\perp\\{ 0,1 \\}(1,100)}$              & 0.20000099999999998 & 10000.0  \\\\\n",
      "2        & alltoall_1_0_-1      & $T_{\\perp\\{ (1,0),\\emptyset \\}(1,\\emptyset)}$ & 1.200002 & 10000.0  \\\\\n",
      "3        & alltoall_minor_0_1_-1 & $T_{\\perp\\{ 1,0 \\}(2,1)}$                & 0.40000099999999994 & 10000.0  \\\\\n",
      "4        & alltoall_1_0_-1      & $T_{\\perp\\{ (0,1),\\emptyset \\}(2,\\emptyset)}$ & 0.40000099999999994 & 10000.0  \\\\\n",
      "5        & changeBlockSize_0_1  & $T_{\\perp\\{ (0,1),\\emptyset \\}(1,\\emptyset)}$ & 0.35000299999999995 & 10000.0  \\\\\n",
      "Total cost: 2.550s\n",
      "CPU times: user 36.1 s, sys: 780 ms, total: 36.9 s\n",
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mem_constrained_dist = tc.optim.AStarRedistributor(tc.optim.IdealLowerBoundsCM(), alpha=ALPHA, beta=BETA, node_filter=mem_constrained_filter, top_k=1)\n",
    "sequence, total_cost = mem_constrained_dist.redistribute(tensor_shape, dist, target_dist)\n",
    "\n",
    "print_path(sequence, tensor_shape)\n",
    "print(f\"Total cost: {total_cost:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explored 85 nodes, found 20 possible paths.\n",
      "Step #   & Operation            & Distribution                             & Cost[s]  & Memory Usage [MB] \\\\\n",
      "0        &                      & $T_{\\perp\\{ 0,1 \\}(100,100)}$            & 0        & 10000.0  \\\\\n",
      "1        & allgather_1          & $T_{\\perp\\{ 0,\\emptyset \\}(100,\\emptyset)}$ & 1.200002 & 40000.0  \\\\\n",
      "2        & split_minor_0_1_1    & $T_{\\perp\\{ (0,1),\\emptyset \\}(25,\\emptyset)}$ & 0.0      & 10000.0  \\\\\n",
      "3        & changeBlockSize_0_1  & $T_{\\perp\\{ (0,1),\\emptyset \\}(1,\\emptyset)}$ & 0.35000299999999995 & 10000.0  \\\\\n",
      "Total cost: 1.55s\n",
      "CPU times: user 2min 20s, sys: 3.58 s, total: 2min 23s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a_star_redist = tc.optim.AStarRedistributor(tc.optim.IdealLowerBoundsCM(), alpha=ALPHA, beta=BETA, path_cost_w=10, estimate_w=1.0, max_depth=5, top_k = 10)\n",
    "sequence, total_cost = a_star_redist.redistribute(tensor_shape, dist, target_dist)\n",
    "\n",
    "print_path(sequence, tensor_shape)\n",
    "print(f\"Total cost: {total_cost:.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorcraft-dev311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
